4:"$Sreact.fragment"
5:I[6154,["839","static/chunks/839-7f2ca11332c314f2.js","177","static/chunks/app/layout-5b0fbb215f9c4aa7.js"],"ThemeProvider"]
6:I[4839,["839","static/chunks/839-7f2ca11332c314f2.js","177","static/chunks/app/layout-5b0fbb215f9c4aa7.js"],""]
7:I[5244,[],""]
8:I[3866,[],""]
a:I[6213,[],"OutletBoundary"]
c:I[6213,[],"MetadataBoundary"]
e:I[6213,[],"ViewportBoundary"]
10:I[4835,[],""]
1:HL["/_next/static/media/4473ecc91f70f139-s.p.woff","font",{"crossOrigin":"","type":"font/woff"}]
2:HL["/_next/static/media/463dafcda517f24f-s.p.woff","font",{"crossOrigin":"","type":"font/woff"}]
3:HL["/_next/static/css/dc73db5bf5904b54.css","style"]
0:{"P":null,"b":"DwF5hgYrAtUQMMF3n6O2R","p":"","c":["","project","transcalibur"],"i":false,"f":[[["",{"children":["project",{"children":["transcalibur",{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$4","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/dc73db5bf5904b54.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":[["$","head",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.css","integrity":"sha384-knaESGLxlQRSHWSJ+ZbTX6/L1bJZWBsBYGb2O+g64XHFuO7CbIj9Pkf1aaVXzIZJ","crossOrigin":"anonymous"}]}],["$","body",null,{"className":"__variable_1e4310 __variable_c3aa02 antialiased","children":[["$","$L5",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":[["$","header",null,{"className":"sticky top-0 z-10 border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60","children":["$","div",null,{"className":"container flex h-14 items-center","children":["$","nav",null,{"className":"flex items-center space-x-4 lg:space-x-6 ml-20","children":[["$","$L6",null,{"href":"/","className":"text-sm font-bold transition-colors hover:text-primary","children":"Jotaro Shigeyama"}],["$","$L6",null,{"href":"/posts","className":"text-sm font-medium text-muted-foreground transition-colors hover:text-primary","children":"Blog"}]]}]}]}],["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}],["$","footer",null,{"className":"mt-20 border-t border-gray-600 py-8 text-center text-sm text-muted-foreground","children":["$","p",null,{"children":"© 2025 Jotaro Shigeyama. All rights reserved. Webpage made by create-next-app@latest."}]}]]}]]}]]}],{"children":["project",["$","$4","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","project","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]]}],{"children":["transcalibur",["$","$4","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","project","children","transcalibur","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]]}],{"children":["__PAGE__",["$","$4","c",{"children":["$L9",null,["$","$La",null,{"children":"$Lb"}]]}],{},null]},null]},null]},null],["$","$4","h",{"children":[null,["$","$4","5BUI023vLgA3n9_l76rTG",{"children":[["$","$Lc",null,{"children":"$Ld"}],["$","$Le",null,{"children":"$Lf"}],["$","meta",null,{"name":"next-size-adjust"}]]}]]}]]],"m":"$undefined","G":["$10","$undefined"],"s":false,"S":true}
11:T2be6,<h3>Downloads:</h3>
<p><a href='/transcalibur/shigeyama-preprint.pdf'>Preprint Paper (PDF 7MB)</a>  //   <a href='/transcalibur/transcalibur-movie.mp4'> Movie (MP3 20MB)</a>   //     <a href='/transcalibur/presskit.zip'> Press Kit (ZIP Archive 20MB)</a></p>
<hr>
<center>
<iframe className='self-center' width="560" height="315" src="https://www.youtube.com/embed/OiSbn6D5kwA?si=FWtMajNyr92leyz3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</center>

<hr>
<br>
<center> Transcalibur: A Weight Shifting Virtual Reality Controller<br> for 2D Shape Rendering based on Computational Perception Model</center>

<h4>Abstract</h4>
<p>Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment.  </p>
<h4>Award:</h4>
<p><img src='/img/hm.png' style='width:30px; min-height:30px; margin-bottom:0px;'> This paper has been awarded a Best Paper Honorable Mention at CHI2019.</p>
<hr>
<img src='/img/transcalibur-teaser.png' width='100%'>

<hr>
<img src='/img/transcalibur-neu.jpg' width='100%'>

<hr>
<img src='/img/transcalibur-neu-zwei.JPG' width='100%'>

<hr>
<h4>Hardware</h4>
<p>The weight moving mechanism is designed to move along the 2D planner space and to be <em>non-backdrivable</em>. The <em>angular mechanism</em> enables to rotate two arms, and <em>weight mechanisms</em> enable to shift the position of the weight module independently.</p>
<center> <img class='half' src='/img/transform.gif'> <img class='half' src='/img/transcalibur-hardware.png'></center>

<hr>
<h4>Computational Perception Model</h4>
<p>Based on the object shown in VR, the shape of the controller that users grasp is dynamically changed so that its shape perception matches the target object.
In our system, we create a computational model that maps mass properties to haptically perceived shape using a data-driven approach.
We correct the perceived shape data of the VR controller with different mass properties through a perceptual experiment and map these data using regression.
From the model, we determine the mass properties of the VR controller that optimizes the perceived shape of the controller to be the target object shown in virtual environment (VE).
In this manner, we can easily and efficiently render an arbitrary 2D shape through the controller.</p>
<p>We assumed a perception model <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> that maps the physical configuration of the controller <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span> to the perceived shape of the wielded object in VR <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span>:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo>:</mo><mi>ϕ</mi><mo>↦</mo><mi>ψ</mi></mrow><annotation encoding="application/x-tex">f: \phi \mapsto \psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">↦</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span></span>
<img src='/img/transcalibur-approach.png'>




<hr>
<h4>Experiments / Results</h4>
<p>In the data collection experiment, we provided the participants with various shapes of the controller and asked them to report the perceived shapes in VE.
This generates matched pairs of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>ϕ</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>ψ</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\phi_i,\psi_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, which are used to build a regression model for the training data. Using the obtained data pairs, we performed regression analysis to build a map <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> from the configurations of the controller onto the perceived shapes.</p>
<img src='/img/dataCollection.jpg'>

<hr>
<p>To measure the validity of the perception model, we conducted validation experiments. The ten virtual shapes were manually determined such that variations in height, width, symmetricity, and asymmetricity of the target shapes could be evaluated. Overall, our perception model succeeded in providing various target shapes in VR for Transcalibur, leaving a few shapes with confusions on shapes 4 and 5 or 8 and 9.</p>
<img src='/img/transcalibur-outputlist.png'>


<center><img class='half' src='/img/transcalibur-confusionmat.png'></center>

<hr>
<h4>Conclusion</h4>
<p>In this paper, we introduced Transcalibur: the weight moving VR controller for 2D haptic shape illusion.
We implemented a hardware prototype, which can change its mass property in 2D planar space, and applied data-driven methods to obtain maps between mass property and perceived shape.
Based on the demonstration and experiment, we succeeded in rendering various shape perceptions through the controller based on pre-computed perception model.
As a future work, we further investigate details on time factor of shape changing in VR, and we aim to develop a simpler design and yet maximizes range of rendering shape.</p>
<hr>
<br>

<p>CHI2019 Technical Paper</p>
<p><em><strong>Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model</strong></em></p>
<h4>Authors:</h4>
<ul>
<li><a href="https://jotaros.github.io">Jotaro Shigeyama</a></li>
<li><a href="https://takeruace.github.io/">Takeru Hashimoto</a></li>
<li><a href="http://www.shigeodayo.com">Shigeo Yoshida</a></li>
<li><a href="http://www.cyber.t.u-tokyo.ac.jp/~narumi/">Takuji Narumi</a></li>
<li><a href="http://www.cyber.t.u-tokyo.ac.jp/">Tomohiro Tanikawa</a></li>
<li>and <a href="https://twitter.com/_anohito">Michitaka Hirose</a></li>
</ul>
<h4>Downloads:</h4>
<p><a href='/transcalibur/shigeyama-preprint.pdf'>Preprint Paper (PDF 7MB)</a> -//-  <a href='/transcalibur/transcalibur-movie.mp4'> Movie (MP3 20MB)</a>  -//-    <a href='/transcalibur/presskit.zip'> Press Kit (ZIP Archive 20MB)</a></p>
<h4>Acknowledgement:</h4>
<p>We thank Yuji Suzuki and Isamu Ohashi for their help during the SIGGRAPH2018 e-tech exhibition. We thank Leo Matsumura for the engineering and development of next-version prototype &quot;Transcalibur-neu&quot;.</p>
<h4>Archive:</h4>
<p>Previously presented SIGGRAPH2018 E-tech Promotion can be seen <a href="http://www.cyber.t.u-tokyo.ac.jp/~jotaro/transcalibur_web/">here.</a></p>
9:["$","div",null,{"className":"max-w-4xl mx-auto px-4 py-8","children":["$","article",null,{"className":"","children":[["$","div",null,{"className":"font-serif","children":"Research"}],["$","h1",null,{"className":"text-4xl font-light mb-2","children":"Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model"}],["$","div",null,{"className":"text-gray-600 mb-12 text-sm","children":"2019-01-01"}],["$","div",null,{"className":"myMarkdown","dangerouslySetInnerHTML":{"__html":"$11"}}]]}]}]
f:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
d:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Jotaro Shigeyama"}],["$","meta","2",{"name":"description","content":"Portfolio website of Dr. Jotaro Shigeyama"}],["$","link","3",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
b:null
